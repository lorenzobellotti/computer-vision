{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORT LIBRERIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "from random import randint\n",
    "import random\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "%matplotlib inline\n",
    "from skimage.io import imread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "#load model dalla cartella Models\n",
    "json_file = open('..\\\\Models\\\\model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "loaded_model.load_weights(\"..\\\\Models\\\\model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#costituisco la directory Inference e seleziono un'immagine dalla cartella nok a scopo di esempio\n",
    "\n",
    "os.chdir('..\\\\Data\\\\Prepared\\\\ok')\n",
    "if os.path.isdir('..\\\\..\\\\Inference') is False:\n",
    "    os.makedirs('..\\\\..\\\\Inference')\n",
    "    \n",
    "    for i in random.sample(glob.glob('ok*'), 0):     #sostituire con 0 lo 1 in caso si voglia un immagine nok\n",
    "        shutil.move(i, '..\\\\..\\\\Inference')\n",
    "os.chdir('..\\\\nok')\n",
    "for i in random.sample(glob.glob('nok*'), 1):        #sostituire con 1 lo 0 in caso si voglia un immagine nok\n",
    "    shutil.move(i, '..\\\\..\\\\Inference')  \n",
    "os.chdir('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename file presenti in Inference\n",
    "\n",
    "def main():\n",
    "   \n",
    "    folder = \"..\\\\Data\\\\Inference\"\n",
    "    for count, filename in enumerate(os.listdir(folder)):\n",
    "        dst = f\"pred{str(count)}.bmp\"\n",
    "        src =f\"{folder}/{filename}\"  \n",
    "        dst =f\"{folder}/{dst}\"\n",
    "        os.rename(src, dst)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lopi1\\anaconda3\\lib\\site-packages\\keras\\engine\\training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m The algorithm predicts, with a probability of 100.0 % that this is a nok image\n"
     ]
    }
   ],
   "source": [
    "#deploy di un immagine ok\n",
    "pred_filenames = os.listdir(\"..\\\\Data\\\\Inference\")\n",
    "pred_df = pd.DataFrame({'filename': pred_filenames})\n",
    "nb_samples = pred_df.shape[0]\n",
    "batch_size = 10\n",
    "pred_gen = ImageDataGenerator(preprocessing_function=tf.keras.applications.inception_v3.preprocess_input)\n",
    "pred_generator = pred_gen.flow_from_dataframe(pred_df, \"..\\\\Data\\\\Inference\", \n",
    "                                              x_col='filename',\n",
    "                                              y_col=None,\n",
    "                                              class_mode=None,\n",
    "                                              batch_size=batch_size,\n",
    "                                              target_size=(299, 299),\n",
    "                                              shuffle=False)\n",
    "X_pred = pred_generator\n",
    "pred = loaded_model.predict(X_pred, verbose=0)\n",
    "rounded_pred = np.argmax(np.round(pred), axis=-1) \n",
    "if rounded_pred[0] == 0:\n",
    "    print(\"\\033[1m The algorithm predicts, with a probability of\", np.round((pred[0,0])*100,2) ,\"% that this is an ok image\")\n",
    "else:\n",
    "    print(\"\\033[1m The algorithm predicts, with a probability of\", np.round((pred[0,1])*100,2) ,\"% that this is a nok image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rimuovo la directory per permettere al processo di essere ripetuto\n",
    "shutil.rmtree('..\\\\Data\\\\Inference')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "04f665aa82a7af270bc849eda0b0b8c3ed818378325e9cbfb80426ce388cfa52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
